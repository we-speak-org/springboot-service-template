# Guide d'utilisation Emergent.sh

Ce document d√©taille comment utiliser ce template avec Emergent.sh pour g√©n√©rer votre microservice.

## üìã Pr√©requis

1. Compte Emergent.sh actif
2. Sp√©cifications fonctionnelles du service (depuis wespeak-specifications)
3. Repository GitHub cr√©√© dans l'organisation we-speak-org

## üöÄ √âtapes de g√©n√©ration

### 1. Pr√©parer les sp√©cifications

Assurez-vous que les sp√©cifications de votre service sont compl√®tes dans le repo `wespeak-specifications` :

```
wespeak-specifications/
‚îî‚îÄ‚îÄ [service-name]/
    ‚îú‚îÄ‚îÄ specification.md
    ‚îú‚îÄ‚îÄ api-endpoints.md
    ‚îú‚îÄ‚îÄ data-models.md
    ‚îú‚îÄ‚îÄ kafka-events.md
    ‚îú‚îÄ‚îÄ diagrams.md
    ‚îî‚îÄ‚îÄ user-stories.md
```

### 2. Cr√©er le repository depuis le template

```bash
# Sur GitHub, cliquer sur "Use this template"
# Ou via GitHub CLI:
gh repo create we-speak-org/[service-name] \
  --template we-speak-org/springboot-service-template \
  --public \
  --clone
```

### 3. Configurer Emergent.sh

#### Prompt initial pour Emergent.sh

```markdown
# G√©n√©ration du [Service Name]

Objectif: Impl√©menter le microservice [service-name] selon les sp√©cifications WeSpeak.

## Stack technique
- Spring Boot 4.0
- Java 21
- MongoDB (base de donn√©es unique)
- Redis (cache)
- Kafka (messaging)
- Keycloak (authentification OAuth2/OIDC)

## Sp√©cifications √† respecter

[Coller ici le contenu de specification.md]

## Mod√®le de donn√©es

[Coller ici le contenu de data-models.md]

## API REST

[Coller ici le contenu de api-endpoints.md]

## √âv√©nements Kafka

[Coller ici le contenu de kafka-events.md]

## Instructions sp√©cifiques

1. **Architecture en couches**
   - Controllers (API REST)
   - Services (logique m√©tier)
   - Repositories (acc√®s donn√©es MongoDB)
   - Kafka Producers/Consumers

2. **Entit√©s MongoDB**
   - Utiliser `@Document(collection = "nom")`
   - Inclure auditing (`@CreatedDate`, `@LastModifiedDate`)
   - Ajouter indexes appropri√©s (`@Indexed`)

3. **DTOs**
   - Request DTOs avec validation (`@Valid`, `@NotNull`, etc.)
   - Response DTOs s√©par√©s (ne jamais exposer les entit√©s directement)
   - Mapper avec MapStruct ou manuellement

4. **Services**
   - Annoter avec `@Service`
   - Utiliser `@Cacheable` pour les op√©rations de lecture fr√©quentes
   - Logger toutes les op√©rations importantes
   - Publier les √©v√©nements Kafka appropri√©s

5. **S√©curit√©**
   - Endpoints prot√©g√©s par d√©faut
   - Utiliser `@PreAuthorize("hasRole('...')")` pour les contr√¥les d'acc√®s
   - Extraire l'utilisateur du JWT via SecurityContextHolder

6. **Tests**
   - Tests unitaires pour tous les services
   - Tests d'int√©gration avec Testcontainers
   - Couverture minimale: 80%

7. **Documentation**
   - Annoter tous les endpoints avec `@Operation`
   - Ajouter des exemples dans les DTOs
   - Documenter les codes d'erreur possibles

## Ordre d'impl√©mentation

1. Mod√®le de donn√©es (entit√©s + repositories)
2. DTOs (request + response)
3. Services (logique m√©tier)
4. Kafka producers/consumers
5. Controllers (API REST)
6. Tests unitaires
7. Tests d'int√©gration
8. Documentation OpenAPI

## Crit√®res de validation

- ‚úÖ Tous les endpoints sp√©cifi√©s sont impl√©ment√©s
- ‚úÖ Les √©v√©nements Kafka sont publi√©s correctement
- ‚úÖ Les tests passent (mvn verify)
- ‚úÖ La couverture de tests est >= 80%
- ‚úÖ Le service d√©marre sans erreur
- ‚úÖ Swagger UI accessible et complet
- ‚úÖ Health checks fonctionnels
- ‚úÖ M√©triques Prometheus expos√©es
```

### 4. It√©rations avec Emergent.sh

#### Phase 1: Mod√®le de donn√©es
```
Impl√©mente le mod√®le de donn√©es avec:
- Toutes les entit√©s MongoDB selon data-models.md
- Repositories Spring Data MongoDB
- Indexes pour optimisation
- Tests unitaires des repositories
```

#### Phase 2: DTOs et Validation
```
Cr√©e les DTOs pour:
- Toutes les requ√™tes API (avec validation Bean Validation)
- Toutes les r√©ponses API
- Mappers entre entit√©s et DTOs
```

#### Phase 3: Services
```
Impl√©mente les services avec:
- Logique m√©tier selon specification.md
- Cache Redis pour les lectures
- Gestion des erreurs appropri√©e
- Logging structur√©
- Tests unitaires (avec Mockito)
```

#### Phase 4: Kafka
```
Impl√©mente:
- Producers pour publier les √©v√©nements selon kafka-events.md
- Consumers pour √©couter les topics pertinents
- S√©rialisation/d√©s√©rialisation JSON
- Tests avec KafkaTest
```

#### Phase 5: Controllers
```
Impl√©mente les controllers REST:
- Tous les endpoints selon api-endpoints.md
- Validation des inputs
- Gestion des erreurs (via GlobalExceptionHandler)
- S√©curit√© (annotations @PreAuthorize)
- Documentation OpenAPI compl√®te
```

#### Phase 6: Tests d'int√©gration
```
Cr√©e les tests d'int√©gration avec Testcontainers:
- MongoDB container
- Kafka container
- Redis container
- Tests end-to-end de tous les endpoints
- V√©rification des √©v√©nements Kafka
```

### 5. Validation finale

#### Checklist avant d√©ploiement

```bash
# Tests
./mvnw clean verify
# Doit afficher: Tests run: X, Failures: 0, Errors: 0

# Build Docker
docker build -t test-service -f docker/Dockerfile .
# Doit se terminer sans erreur

# D√©marrage local
docker-compose up -d
./mvnw spring-boot:run
# V√©rifier les logs: aucune erreur

# Health checks
curl http://localhost:8081/actuator/health
# Doit retourner: {"status":"UP"}

# Swagger UI
open http://localhost:8081/swagger-ui.html
# V√©rifier que tous les endpoints sont document√©s

# M√©triques
curl http://localhost:8081/actuator/prometheus
# Doit retourner les m√©triques
```

## üêõ D√©pannage courant

### Erreur: MongoDB connection failed
```bash
# V√©rifier que MongoDB est d√©marr√©
docker-compose ps mongodb
# V√©rifier la connection string dans .env
```

### Erreur: Kafka not available
```bash
# V√©rifier Kafka et Zookeeper
docker-compose logs kafka
# Attendre que Kafka soit compl√®tement d√©marr√© (peut prendre 30s)
```

### Erreur: JWT validation failed
```bash
# V√©rifier Keycloak
curl http://localhost:8080/realms/wespeak
# Configurer le realm 'wespeak' dans Keycloak admin
```

### Tests √©chouent avec Testcontainers
```bash
# V√©rifier Docker
docker ps
# S'assurer que Docker Desktop est d√©marr√©
# V√©rifier DOCKER_HOST si WSL2
```

## üìö Ressources Emergent.sh

### Prompts utiles

**Ajouter un nouvel endpoint:**
```
Ajoute un endpoint GET /api/resource/{id} qui:
- R√©cup√®re une ressource par ID
- Retourne 404 si non trouv√©
- Cache le r√©sultat dans Redis (TTL: 10 minutes)
- N√©cessite le role USER
- Documente avec OpenAPI
- Ajoute les tests unitaires et d'int√©gration
```

**Optimiser les performances:**
```
Optimise les performances de [m√©thode/endpoint]:
- Ajoute un cache Redis appropri√©
- Optimise la requ√™te MongoDB (projection, index)
- Ajoute du logging de performance
- Mesure avec Micrometer
```

**Corriger un bug:**
```
Bug: [description du probl√®me]
Comportement attendu: [...]
Comportement actuel: [...]
Logs d'erreur: [...]

Analyse et corrige le bug en:
1. Identifiant la cause racine
2. Proposant une solution
3. Ajoutant un test pour √©viter la r√©gression
```

## ‚úÖ Crit√®res de succ√®s

Un service est consid√©r√© complet quand:

- [ ] Tous les endpoints API sont impl√©ment√©s et test√©s
- [ ] Tous les √©v√©nements Kafka sont produits/consomm√©s correctement
- [ ] Couverture de tests >= 80%
- [ ] Aucune erreur dans les logs au d√©marrage
- [ ] Health checks OK (MongoDB, Redis, Kafka)
- [ ] Swagger UI complet et √† jour
- [ ] M√©triques Prometheus expos√©es
- [ ] L'image Docker build sans erreur
- [ ] Le service d√©marre dans docker-compose
- [ ] La documentation est √† jour (README, API docs)

## üö¢ D√©ploiement

Une fois valid√© localement:

```bash
# Commit et push
git add .
git commit -m "feat: implement [service-name] according to specs"
git push origin main

# Le GitHub Action build automatiquement
# V√©rifier: https://github.com/we-speak-org/[service-name]/actions
```

L'image Docker sera publi√©e sur:
`ghcr.io/we-speak-org/[service-name]:latest`

---

**Note**: Ce guide suppose une utilisation interactive avec Emergent.sh. Adaptez les prompts selon vos besoins sp√©cifiques et les retours de l'IA.
